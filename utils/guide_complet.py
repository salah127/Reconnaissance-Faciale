"""
SYST√àME DE RECONNAISSANCE FACIALE BINAIRE
==========================================

Objectif: D√©velopper un syst√®me de reconnaissance faciale avec CNN qui:
- Analyse des images en entr√©e (64x64 pixels en niveaux de gris)
- Retourne un r√©sultat binaire: 1 si l'image correspond √† l'utilisateur, 0 sinon
- Utilise l'augmentation de donn√©es pour √©quilibrer le dataset d√©s√©quilibr√©
- Produit UN SEUL mod√®le final optimis√© avec seuil adaptatif

Architecture: CNN avec couches convolutionnelles + pooling + dense
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.utils.class_weight import compute_class_weight

# === √âTAPE 1: CHARGER LES DONN√âES ===
print(" Chargement des donn√©es...")

data = np.load("./data/my_faces_augmented.npy")
print(f" Donn√©es charg√©es: {data.shape}")
print(f"   Range: {data.min():.3f} - {data.max():.3f}")

# === √âTAPE 2: CR√âER LES TARGETS √Ä PARTIR DES DONN√âES ===
print("\n √âTAPE 2: Cr√©ation des labels automatiques...")

USER_ID = 0  # Choisir quelle personne reconna√Ætre (0 √† 39)

def create_binary_labels(total_images=400, images_per_person=10, target_person_id=0):
    """Cr√©e les labels binaires bas√©s sur la structure du dataset"""
    y_binary = np.zeros(total_images)
    start_idx = target_person_id * images_per_person
    end_idx = start_idx + images_per_person
    y_binary[start_idx:end_idx] = 1
    return y_binary.astype(int)

# Cr√©er les labels
y_binary = create_binary_labels(target_person_id=USER_ID)

print(f" Labels cr√©√©s automatiquement:")
print(f"   Personne {USER_ID}: images {USER_ID*10} √† {USER_ID*10+9} = Utilisateur (1)")
print(f"   Total images utilisateur: {np.sum(y_binary)} ({np.sum(y_binary)/len(y_binary)*100:.1f}%)")
print(f"   Total images autres: {len(y_binary) - np.sum(y_binary)} ({(len(y_binary) - np.sum(y_binary))/len(y_binary)*100:.1f}%)")
print(f"  D√âS√âQUILIBRE: 2.5% utilisateur vs 97.5% autres!")

# === √âTAPE 3: VISUALISER QUELQUES EXEMPLES ===
print("\n Visualisation des donn√©es...")

def show_user_vs_others(data, labels, user_id=0):
    """Montre quelques images de l'utilisateur vs autres"""
    fig, axes = plt.subplots(2, 5, figsize=(15, 6))
    
    # Images de l'utilisateur (premi√®re ligne)
    user_indices = np.where(labels == 1)[0][:5]
    for i, idx in enumerate(user_indices):
        axes[0, i].imshow(data[idx], cmap='gray')
        axes[0, i].set_title(f'Utilisateur {user_id}\n(Image {idx})')
        axes[0, i].axis('off')
    
    # Images d'autres personnes (deuxi√®me ligne)  
    other_indices = np.where(labels == 0)[0][:5]
    for i, idx in enumerate(other_indices):
        axes[1, i].imshow(data[idx], cmap='gray')
        person_id = idx // 10
        axes[1, i].set_title(f'Personne {person_id}\n(Image {idx})')
        axes[1, i].axis('off')
    
    plt.suptitle(f'UTILISATEUR {user_id} vs AUTRES PERSONNES', fontsize=16)
    plt.tight_layout()
    plt.show()

# Afficher les exemples
show_user_vs_others(data, y_binary, USER_ID)

print("\n √âquilibrage des donn√©es...")




def equilibrer_donnees(data, labels, methode="sur_echantillonnage_intelligent"):
    """
    √âquilibre les classes avec augmentation de donn√©es intelligente
    
    Args:
        data: images
        labels: √©tiquettes
        methode: "sous_echantillonnage", "sur_echantillonnage", ou "sur_echantillonnage_intelligent"
    
    Returns:
        data_eq, labels_eq: donn√©es √©quilibr√©es
    """
    from sklearn.utils import resample
    
    # Indices des classes
    indices_user = np.where(labels == 1)[0]  # 10 images
    indices_others = np.where(labels == 0)[0]  # 390 images
    
    print(f"   Avant √©quilibrage:")
    print(f"   - Utilisateur: {len(indices_user)} images")
    print(f"   - Autres: {len(indices_others)} images")
    
    if methode == "sous_echantillonnage":
        # Prendre plus d'images d'autres personnes pour avoir assez de donn√©es
        np.random.seed(42)
        indices_others_reduits = np.random.choice(indices_others, size=len(indices_user)*6, replace=False)
        
        # Combiner
        indices_finaux = np.concatenate([indices_user, indices_others_reduits])
        
    elif methode == "sur_echantillonnage_intelligent":
        # Strat√©gie intelligente: dupliquer P0 et prendre plus d'autres personnes
        np.random.seed(42)
        
        # Dupliquer les images P0 avec transformations l√©g√®res
        def augmenter_image(img):
            """Applique des transformations l√©g√®res √† une image"""
            try:
                # Essayer avec scipy si disponible
                from scipy.ndimage import rotate
                angle = np.random.uniform(-10, 10)
                img_transformed = rotate(img, angle, reshape=False, cval=img.mean())
            except ImportError:
                # Alternative sans scipy : translation l√©g√®re
                shift_x = np.random.randint(-3, 4)
                shift_y = np.random.randint(-3, 4)
                img_transformed = np.roll(img, shift_x, axis=0)
                img_transformed = np.roll(img_transformed, shift_y, axis=1)
            
            # Bruit l√©ger
            noise = np.random.normal(0, 0.01, img_transformed.shape)  # Moins de bruit
            img_noise = np.clip(img_transformed + noise, 0, 1)
            
            # Variation de contraste l√©g√®re
            contrast_factor = np.random.uniform(0.9, 1.1)
            img_final = np.clip(img_noise * contrast_factor, 0, 1)
            
            return img_final
        
        # Cr√©er plus d'exemples de P0 avec augmentation
        data_user_augmented = []
        labels_user_augmented = []
        
        # Garder les originaux
        for idx in indices_user:
            data_user_augmented.append(data[idx])
            labels_user_augmented.append(1)
        
        # Ajouter des versions augment√©es (4x plus)
        for _ in range(4):
            for idx in indices_user:
                img_augmented = augmenter_image(data[idx])
                data_user_augmented.append(img_augmented)
                labels_user_augmented.append(1)
        
        # Prendre un √©chantillon d'autres personnes (m√™me quantit√© que P0 augment√©)
        nb_autres_needed = len(data_user_augmented)
        indices_others_selected = np.random.choice(indices_others, size=nb_autres_needed, replace=False)
        
        # Combiner toutes les donn√©es
        data_finale = data_user_augmented + [data[idx] for idx in indices_others_selected]
        labels_finale = labels_user_augmented + [0] * len(indices_others_selected)
        
        # Convertir en arrays
        data_eq = np.array(data_finale)
        labels_eq = np.array(labels_finale)
        
        # M√©langer
        shuffle_indices = np.random.permutation(len(data_eq))
        data_eq = data_eq[shuffle_indices]
        labels_eq = labels_eq[shuffle_indices]
        
        print(f"   Apr√®s √©quilibrage ({methode}):")
        print(f"   - Utilisateur: {np.sum(labels_eq)} images ({np.sum(labels_eq)/len(labels_eq)*100:.1f}%)")
        print(f"   - Autres: {len(labels_eq) - np.sum(labels_eq)} images ({(len(labels_eq) - np.sum(labels_eq))/len(labels_eq)*100:.1f}%)")
        print(f"   - Total: {len(data_eq)} images")
        
        return data_eq, labels_eq
        
    elif methode == "sur_echantillonnage":
        # Sur-√©chantillonnage simple avec resample
        data_user = data[indices_user]
        data_others = data[indices_others]
        labels_user = labels[indices_user]
        labels_others = labels[indices_others]
        
        # Sur-√©chantillonner les utilisateurs
        data_user_resampled, labels_user_resampled = resample(
            data_user, labels_user, 
            n_samples=len(indices_others), 
            random_state=42
        )
        
        # Combiner
        data_eq = np.concatenate([data_user_resampled, data_others])
        labels_eq = np.concatenate([labels_user_resampled, labels_others])
        
    # M√©langer pour les m√©thodes simples
    if methode != "sur_echantillonnage_intelligent":
        shuffle_indices = np.random.permutation(len(data_eq))
        data_eq = data_eq[shuffle_indices]
        labels_eq = labels_eq[shuffle_indices]
        
        print(f"   Apr√®s √©quilibrage ({methode}):")
        print(f"   - Utilisateur: {np.sum(labels_eq)} images ({np.sum(labels_eq)/len(labels_eq)*100:.1f}%)")
        print(f"   - Autres: {len(labels_eq) - np.sum(labels_eq)} images ({(len(labels_eq) - np.sum(labels_eq))/len(labels_eq)*100:.1f}%)")
    
    return data_eq, labels_eq





# √âquilibrer avec augmentation intelligente
data_eq, y_eq = equilibrer_donnees(data, y_binary, methode="sur_echantillonnage_intelligent")

# === √âTAPE 5: PR√âPARER LES DONN√âES √âQUILIBR√âES ===
print("\n Pr√©paration des donn√©es √©quilibr√©es...")

# Aplatir pour division
X_flat_eq = data_eq.reshape(data_eq.shape[0], -1)

# Division train/val/test
X_temp, X_test, y_temp, y_test = train_test_split(
    X_flat_eq, y_eq, 
    test_size=0.3,  # Plus de test car moins de donn√©es
    random_state=42,
    stratify=y_eq
)

X_train, X_val, y_train, y_val = train_test_split(
    X_temp, y_temp, 
    test_size=0.3, 
    random_state=42,
    stratify=y_temp
)

print(f" Donn√©es √©quilibr√©es pr√©par√©es:")
print(f"   Train: {X_train.shape} - Utilisateur: {np.sum(y_train)}/{len(y_train)} ({np.sum(y_train)/len(y_train)*100:.1f}%)")
print(f"   Val: {X_val.shape} - Utilisateur: {np.sum(y_val)}/{len(y_val)} ({np.sum(y_val)/len(y_val)*100:.1f}%)")
print(f"   Test: {X_test.shape} - Utilisateur: {np.sum(y_test)}/{len(y_test)} ({np.sum(y_test)/len(y_test)*100:.1f}%)")

# === √âTAPE 6: REFORMATER POUR LE CNN ===
print("\nüîÑ √âTAPE 6: Reformatage pour CNN...")

def prepare_data_for_cnn(X_train, X_val, X_test):
    """Transforme les donn√©es pour le CNN"""
    X_train_cnn = X_train.reshape(-1, 64, 64, 1)
    X_val_cnn = X_val.reshape(-1, 64, 64, 1)  
    X_test_cnn = X_test.reshape(-1, 64, 64, 1)
    return X_train_cnn, X_val_cnn, X_test_cnn

X_train_cnn, X_val_cnn, X_test_cnn = prepare_data_for_cnn(X_train, X_val, X_test)

print(f" Donn√©es reformat√©es pour CNN:")
print(f"   X_train_cnn: {X_train_cnn.shape}, range: {X_train_cnn.min():.3f}-{X_train_cnn.max():.3f}")

# === √âTAPE 7: CR√âER ET COMPILER LE MOD√àLE ===
print("\n √âTAPE 7: Cr√©ation du mod√®le...")

try:
    from keras.models import Sequential
    from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten
    from keras.optimizers import Adam
    
    def create_improved_cnn():
        """Cr√©e un CNN am√©lior√© pour reconnaissance faciale"""
        model = Sequential([
            # Premi√®re couche avec normalisation
            Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 1), padding='same'),
            Conv2D(32, (3, 3), activation='relu', padding='same'),
            MaxPooling2D((2, 2)),
            Dropout(0.25),
            
            # Deuxi√®me bloc
            Conv2D(64, (3, 3), activation='relu', padding='same'),
            Conv2D(64, (3, 3), activation='relu', padding='same'),
            MaxPooling2D((2, 2)),
            Dropout(0.25),
            
            # Troisi√®me bloc
            Conv2D(128, (3, 3), activation='relu', padding='same'),
            Conv2D(128, (3, 3), activation='relu', padding='same'),
            MaxPooling2D((2, 2)),
            Dropout(0.25),
            
            # Couches denses
            Flatten(),
            Dense(256, activation='relu'),
            Dropout(0.5),
            Dense(128, activation='relu'),
            Dropout(0.3),
            Dense(1, activation='sigmoid')
        ])
        
        # Compilation avec optimiseur adaptatif
        model.compile(
            optimizer=Adam(learning_rate=0.0005),  # Learning rate plus faible
            loss='binary_crossentropy',
            metrics=['accuracy', 'precision', 'recall']
        )
        
        return model
    
    # Cr√©er le mod√®le am√©lior√©
    model = create_improved_cnn()
    
    print(" Mod√®le cr√©√© et compil√©!")
    print("\n Architecture du mod√®le:")
    model.summary()
    
    # === √âTAPE 8: ENTRA√éNEMENT √âQUILIBR√â ===
    print("\n √âTAPE 8: Entra√Ænement du mod√®le √©quilibr√©...")
    
    # V√©rification
    print(f" V√©rification avant entra√Ænement:")
    print(f"   Shape entr√©e: {X_train_cnn.shape}")
    print(f"   Labels distribution: {np.unique(y_train, return_counts=True)}")
    
    # Entra√Ænement avec callbacks pour √©viter le sur-apprentissage
    from keras.callbacks import EarlyStopping, ReduceLROnPlateau
    
    callbacks = [
        EarlyStopping(
            monitor='val_accuracy',
            patience=15,  # Plus de patience
            restore_best_weights=True,
            verbose=1,
            min_delta=0.001  # Am√©lioration minimale
        ),
        ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.3,
            patience=8,
            min_lr=0.00001,
            verbose=1
        )
        # Suppression du ModelCheckpoint - on garde seulement le mod√®le final
    ]
    
    # Calculer les poids des classes pour l'entra√Ænement
    from sklearn.utils.class_weight import compute_class_weight
    
    class_weights = compute_class_weight(
        'balanced',
        classes=np.unique(y_train),
        y=y_train
    )
    class_weight_dict = {0: class_weights[0], 1: class_weights[1]}
    
    print(f" Poids des classes: {class_weight_dict}")
    
    history = model.fit(
        X_train_cnn, y_train,
        validation_data=(X_val_cnn, y_val),
        epochs=100,  # Plus d'√©poques avec early stopping
        batch_size=16,  # Batch size adapt√©
        verbose=1,
        callbacks=callbacks,
        class_weight=class_weight_dict  # Utiliser les poids √©quilibr√©s
    )
    
    print(" Entra√Ænement termin√©!")
    
    # === √âTAPE 9: √âVALUATION COMPL√àTE AVEC CALCUL DE SEUIL OPTIMAL ===
    print("\n √âTAPE 9: √âvaluation compl√®te...")
    
    # Test sur toutes les images de la personne 0 du dataset original
    print(f"\n Test sur TOUTES les images de la personne 0:")
    predictions_p0 = []
    for i in range(10):
        test_img = data[i].reshape(1, 64, 64, 1)
        pred = model.predict(test_img, verbose=0)[0][0]
        predictions_p0.append(pred)
        print(f"   Image {i}: {pred:.3f}")
    
    # Test sur autres personnes
    print(f"\n Test sur autres personnes:")
    predictions_autres = []
    test_autres = [10, 25, 50, 100, 200, 300]  # Plus d'exemples
    for i in test_autres:
        test_img = data[i].reshape(1, 64, 64, 1)
        pred = model.predict(test_img, verbose=0)[0][0]
        predictions_autres.append(pred)
        personne = i // 10
        print(f"   Image {i} (pers.{personne}): {pred:.3f}")
    
    # Calcul des statistiques
    moyenne_p0 = np.mean(predictions_p0)
    moyenne_autres = np.mean(predictions_autres)
    std_p0 = np.std(predictions_p0)
    std_autres = np.std(predictions_autres)
    
    print(f"\n STATISTIQUES DES PR√âDICTIONS:")
    print(f"   Personne 0: moyenne={moyenne_p0:.3f}, std={std_p0:.3f}")
    print(f"   Autres: moyenne={moyenne_autres:.3f}, std={std_autres:.3f}")
    
    # Calcul du seuil optimal plus intelligent
    seuil_milieu = (moyenne_p0 + moyenne_autres) / 2
    
    # Si les distributions se chevauchent beaucoup, utiliser un seuil plus bas
    if abs(moyenne_p0 - moyenne_autres) < 0.1:
        seuil_optimal = min(moyenne_p0 - std_p0/2, 0.3)  # Seuil plus bas
        print("  Distributions tr√®s proches, seuil abaiss√©")
    else:
        seuil_optimal = max(0.3, min(0.7, seuil_milieu))  # Seuil normal
    
    print(f"   Seuil calcul√© (milieu): {seuil_milieu:.3f}")
    print(f"   Seuil optimal choisi: {seuil_optimal:.3f}")
    
    # Test avec une plage de seuils plus large
    print(f"\n √âVALUATION AVEC DIFF√âRENTS SEUILS:")
    seuils_test = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]
    meilleur_seuil = 0.3
    meilleure_precision = 0
    meilleur_f1 = 0
    
    for seuil in seuils_test:
        # Test P0
        correct_p0 = sum(1 for p in predictions_p0 if p > seuil)
        # Test autres
        correct_autres = sum(1 for p in predictions_autres if p <= seuil)
        
        # Calcul des m√©triques
        true_positives = correct_p0
        false_negatives = 10 - correct_p0
        true_negatives = correct_autres
        false_positives = len(predictions_autres) - correct_autres
        
        # Pr√©cision et rappel
        precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0
        recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0
        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
        
        accuracy = (true_positives + true_negatives) / (10 + len(predictions_autres))
        
        print(f"   Seuil {seuil}: P0={correct_p0}/10 ({correct_p0*10}%), Autres={correct_autres}/{len(predictions_autres)}, Acc={accuracy:.1%}, F1={f1_score:.3f}")
        
        # Crit√®re am√©lior√©: F1-score √©lev√© ET au moins 60% de d√©tection P0
        if correct_p0 >= 6 and f1_score > meilleur_f1:
            meilleur_f1 = f1_score
            meilleure_precision = accuracy
            meilleur_seuil = seuil
    
    print(f"\n MEILLEUR SEUIL TROUV√â: {meilleur_seuil}")
    
    # √âvaluation finale avec le meilleur seuil
    bonnes_detections = sum(1 for p in predictions_p0 if p > meilleur_seuil)
    bonnes_rejections = sum(1 for p in predictions_autres if p <= meilleur_seuil)
    
    print(f"\n R√âSULTATS AVEC SEUIL OPTIMAL ({meilleur_seuil}):")
    print(f"   D√©tection personne 0: {bonnes_detections}/10 ({bonnes_detections*10}%)")
    print(f"   Rejet autres: {bonnes_rejections}/{len(test_autres)} ({bonnes_rejections*100//len(test_autres)}%)")
    
    # √âvaluation sur ensemble de test √©quilibr√©
    test_results = model.evaluate(X_test_cnn, y_test, verbose=0)
    test_accuracy = test_results[1]  # L'accuracy est le deuxi√®me √©l√©ment
    print(f"\n Pr√©cision sur test √©quilibr√©: {test_accuracy:.3f} ({test_accuracy*100:.1f}%)")
    
    # === √âTAPE 10: SAUVEGARDE ===
    print("\n √âTAPE 10: Sauvegarde...")
    
    # Nettoyer les fichiers temporaires s'ils existent
    import os
    if os.path.exists('best_model_temp.h5'):
        os.remove('best_model_temp.h5')
        print(" Fichier temporaire supprim√©")
    
    # Sauvegarder le mod√®le final unique
    model.save(f'./test/modele_user_{USER_ID}.h5')
    print(f" Mod√®le unique sauvegard√©: modele_user_{USER_ID}.h5")
    
    # Sauvegarde des informations de seuil
    import json
    seuil_info = {
        'seuil_optimal': float(meilleur_seuil),
        'moyenne_p0': float(moyenne_p0),
        'moyenne_autres': float(moyenne_autres),
        'std_p0': float(std_p0),
        'std_autres': float(std_autres),
        'precision_avec_seuil': float(meilleure_precision)
    }
    
    with open(f'seuil_user_{USER_ID}.json', 'w') as f:
        json.dump(seuil_info, f, indent=2)
    print(f" Informations de seuil sauv√©es: seuil_user_{USER_ID}.json")
    
    # R√©sum√© final
    precision_globale = (bonnes_detections + bonnes_rejections) / (10 + len(test_autres)) * 100
    
  
    print(f" Syst√®me pr√™t pour la reconnaissance faciale binaire !")
    
except Exception as e:
    print(f" Erreur: {e}")
    import traceback
    traceback.print_exc()

print(f"\n Syst√®me de reconnaissance faciale binaire cr√©√© avec succ√®s!")
print(f" Mod√®le unique disponible: modele_user_{USER_ID}.h5")
print(f" Testez avec: python test.py")